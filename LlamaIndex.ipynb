{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGOp5mp92fTE",
        "outputId": "c9ab8e72-cd26-49ea-ae32-b25eacbd1b73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m51.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m56.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m189.0/189.0 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m51.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "%pip install -Uq llama-index"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = getpass.getpass(\"OpenAI API Key: \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IT96WMwA2nBC",
        "outputId": "ab1c25ff-05e2-444d-fe9b-51b4c39b7d01"
      },
      "execution_count": 3,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OpenAI API Key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
        "\n",
        "documents = SimpleDirectoryReader(\"data\").load_data()\n",
        "index = VectorStoreIndex.from_documents(documents)\n",
        "query_engine = index.as_query_engine()"
      ],
      "metadata": {
        "id": "263t00pl4vmX"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from textwrap import fill\n",
        "\n",
        "response = query_engine.query(\"How to prepare YOLO for FPGA?\")\n",
        "print(\"Response:\", fill(response.response, width=72))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVZ82nPa4v95",
        "outputId": "e7df39f7-6311-4541-ff7b-48e48fd8dddf"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response: To prepare YOLO for FPGA, you need to follow a series of steps which\n",
            "include quantization to reduce memory usage and computation on FPGAs by\n",
            "performing INT 8-bit quantization and modifying operations for\n",
            "quantization. After quantization, you need to compile the model to the\n",
            "architecture of the FPGA, optimizing it for DPU utilization and changing\n",
            "the activation function for DPU compatibility. Additionally, you should\n",
            "implement operations not supported by the DPU and post-process the\n",
            "resulting values into an interpretable form using YOLO_post_process.\n",
            "Finally, run the model on the target board (ZCU102) by implementing\n",
            "additional FPGA unsupported operators and supporting the operation list.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nDocuments Used in Query:\")\n",
        "\n",
        "# Loop through source nodes to display document details and content\n",
        "for idx, node in enumerate(response.source_nodes, start=1):\n",
        "    metadata = node.node.metadata\n",
        "    print(f\"\\nDocument {idx}:\")\n",
        "    print(f\"  - File Name: {metadata['file_name']}\")\n",
        "    print(f\"  - Page: {metadata.get('page_label', 'N/A')}\")\n",
        "    print(f\"  - File Path: {metadata['file_path']}\")\n",
        "    print(\"  - Content:\\n\" + fill(node.node.text[:500], width=72) + \"...\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aOqIg1f36cbK",
        "outputId": "ab70aa95-8596-489b-9950-b6becbd46733"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Documents Used in Query:\n",
            "\n",
            "Document 1:\n",
            "  - File Name: Class08-AI-Accellerator-FPGA-cs632-2024fall.pdf\n",
            "  - Page: 33\n",
            "  - File Path: /content/data/Class08-AI-Accellerator-FPGA-cs632-2024fall.pdf\n",
            "  - Content:\n",
            "Preparing Object Detection Model(YOLO) for FPGA • Quantization • -\n",
            "Reduce Memory Usage, Computation on FPGAs • - Performing INT 8-bit\n",
            "quantization • - Modify operations for quantization • Compilation  •\n",
            "Compile to the architecture of the FPGA (ZCU102) • Optimized for DPU\n",
            "utilization • Change activation function for DPU compatibility •\n",
            "YOLO_post_process : Implement operations not supported by the DPU and\n",
            "post-process the resulting values into an interpretable form. • Run\n",
            "Model  • Implement addit...\n",
            "\n",
            "Document 2:\n",
            "  - File Name: Class08-AI-Accellerator-FPGA-cs632-2024fall.pdf\n",
            "  - Page: 34\n",
            "  - File Path: /content/data/Class08-AI-Accellerator-FPGA-cs632-2024fall.pdf\n",
            "  - Content:\n",
            "Exercise • Using Vitis AI 3.0 build YOLOv8&v10 xmodel file which can run\n",
            "in ZCU 102 board • Prerequires • Ubuntu based OS system • Docker • >5GB\n",
            "Storage • Vitis AI 3.0 github repo clone • $ git clone\n",
            "https://github.com/Xilinx/Vitis-AI.git • $ docker pull\n",
            "–platform=linux/amd64 xilinx/vitis-ai-pytorch-cpu:latest • $ docker\n",
            "images  CS632 35...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i0mellJR6k2H"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}